{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_currencies = ['MXN','JPY','INR','HKD','GBP','EUR','CNY','CHF','CAD','AUD']\n",
    "lag = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "import quandl as qd\n",
    "qd.ApiConfig.api_key = \"_4PBEc5xxKVoQoYxWcgG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_currency(cur):\n",
    "    return qd.get('CUR/'+cur,transformation=\"rdiff\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pgmpy.models import BayesianModel\n",
    "import abc\n",
    "import xml.etree.ElementTree as ET #a pretty well-documented xml module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Basic:\n",
    "    \n",
    "    def __init__( self, params, start=0,lag=0):\n",
    "        self.list_of_params = params\n",
    "        self.time_frame = range(start,start+lag+1)\n",
    "        self.model = BayesianModel()\n",
    "        for t in self.time_frame:\n",
    "            for s in params:\n",
    "                self.model.add_node(Basic.get(s,t))\n",
    "        \n",
    "    @staticmethod\n",
    "    def get(param, lag):\n",
    "        return param+'_'+str(lag)\n",
    "    \n",
    "    def store_xml(self, name):\n",
    "        node2pos = dict()\n",
    "        node_space = 200\n",
    "        for i in range(len(self.list_of_params)):\n",
    "            for j in self.time_frame:\n",
    "                node2pos[Basic.get(self.list_of_params[i],j)]=(i*node_space,(j-self.time_frame[0])*node_space)\n",
    "        bif = ET.Element(\"BIF\")\n",
    "        network = ET.SubElement(bif, \"NETWORK\")\n",
    "        bif.set (\"VERSION\",\"\"\"0.3\"\"\")\n",
    "        ET.SubElement(network, \"NAME\").text = \"bayesiannetwork\"\n",
    "        for node in self.model.nodes():\n",
    "            var = ET.SubElement(network,\"VARIABLE\")\n",
    "            var.set(\"TYPE\",\"\"\"nature\"\"\")\n",
    "            ET.SubElement(var,\"NAME\").text = node\n",
    "            ET.SubElement(var,\"OUTCOME\").text = \"increase\"\n",
    "            ET.SubElement(var,\"OUTCOME\").text = \"decrease\"\n",
    "            ET.SubElement(var,\"PROPERTY\").text = \"position =\" + str(node2pos[node])\n",
    "        for node in self.model.nodes():\n",
    "            cpd = ET.SubElement(network,\"DEFINITION\")\n",
    "            ET.SubElement(cpd,\"FOR\").text = node\n",
    "            number_of_parents = len(self.model.get_parents(node))\n",
    "            for par in self.model.get_parents(node):\n",
    "                ET.SubElement(cpd,\"GIVEN\").text = par\n",
    "            s = \" \"\n",
    "            for i in range(2*2**number_of_parents):\n",
    "                s+=\"0.5 \"\n",
    "            ET.SubElement(cpd,\"TABLE\").text = s\n",
    "        tree = ET.ElementTree(bif)\n",
    "        file_name = '{}.xml'.format(name)\n",
    "        tree.write(file_name)\n",
    "                \n",
    "    def generate_table(self):\n",
    "        self.table = pd.DataFrame()\n",
    "        col_names = []\n",
    "        for cur in self.list_of_params:\n",
    "            data = get_currency(cur)\n",
    "            data.RATE = list(map(lambda x: '1' if x>=0 else '0',data.RATE)) # 1 for \"increase\", 0 for \"decrease\"\n",
    "            for i in range(self.time_frame[0]):\n",
    "                data=data.shift(1)\n",
    "            for l in self.time_frame:\n",
    "                self.table=pd.concat([self.table,data],axis=1)\n",
    "                data=data.shift(1)\n",
    "                col_names.append(Basic.get(cur,l))\n",
    "        self.table.columns = col_names\n",
    "        \n",
    "    def load_table(self,name):\n",
    "        file_name = '{}.dat'.format(name)\n",
    "        self.table = pd.read_csv( file_name, parse_dates=[0] )\n",
    "        self.table.replace('N/A',np.nan,inplace=True)\n",
    "        self.table.replace(1.0,'1',inplace=True)\n",
    "        self.table.replace(0.0,'0',inplace=True)\n",
    "        \n",
    "    def train(self):\n",
    "        self.model.fit(data=self.table,complete_samples_only=True)\n",
    "    \n",
    "    def query(self, target, observation={}):\n",
    "        df = pd.DataFrame(list(observation.values()))\n",
    "        df = df.T\n",
    "        df.columns = list(observation.keys())\n",
    "        print(df)\n",
    "        probs = self.model.predict_probability(data=df)\n",
    "        print(probs)\n",
    "        ans = {}\n",
    "        for var in target:\n",
    "            state=0\n",
    "            p = []\n",
    "            while (True):\n",
    "                col_name = Basic.get(var,state)\n",
    "                print(col_name)\n",
    "                if (col_name in probs.columns):\n",
    "                    p.append(probs[col_name][0])\n",
    "                else:\n",
    "                    break\n",
    "                state += 1\n",
    "            ans[var]=p\n",
    "        return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNGrid(Basic):\n",
    "    def __init__( self, params,depth,start=0,lag=0):\n",
    "        if (depth>lag):\n",
    "            raise\n",
    "        super().__init__(params,start,lag)\n",
    "        for t in range(start,start+lag+1):\n",
    "            for s in params:\n",
    "                x = BNFull.get(s,t)\n",
    "                for tt in range(t+1,min(start+lag+1,t+depth+1)):\n",
    "                    for ss in params:\n",
    "                        par = BNFull.get(ss,tt)\n",
    "                        self.model.add_edge(par,x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNFull(BNGrid):\n",
    "    def __init__( self, params,start=0,lag=0):\n",
    "        super().__init__(params,depth=1,start=start,lag=lag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BNCascade(BNFull):\n",
    "    def __init__(self,params,lag,target):\n",
    "        super().__init__(params,start=1,lag=lag-1)\n",
    "        target = BNCascade.get(target,0)\n",
    "        self.model.add_node(target)\n",
    "        for x in self.model.nodes():\n",
    "            if (x!=target):\n",
    "                self.model.add_edge(x,target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_table(table,name):\n",
    "    t = table.copy()\n",
    "    t.replace(np.nan,'N/A',inplace=True)\n",
    "    file_name = '{}.dat'.format(name)\n",
    "    t.to_csv( file_name, index = False )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "network = BNFull(params=list_of_currencies,lag=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "#network.generate_table()\n",
    "network.load_table('dataforsamiam') #!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.store_xml('xmlforsamiam') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store_table(network.table,'dataforsamiam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   EUR_1  EUR_2\n",
      "0      1      0\n"
     ]
    }
   ],
   "source": [
    "network.query(['EUR_0'],{'EUR_1':1,'EUR_2':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "network.table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
